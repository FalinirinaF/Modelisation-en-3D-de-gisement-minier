import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from scripts.data_processor import MiningDataProcessor
from scripts.visualization_3d import Mining3DVisualizer
import io
from scripts.data_validator import DataValidator

# Configuration de la page
st.set_page_config(
    page_title="Mod√©lisation 3D de Gisement Minier",
    page_icon="‚õèÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation des classes
@st.cache_resource
def init_processors():
    processor = MiningDataProcessor()
    visualizer = Mining3DVisualizer()
    return processor, visualizer

processor, visualizer = init_processors()

# Interface utilisateur
st.title("‚õèÔ∏è Mod√©lisation 3D de Gisement Minier")
st.markdown("---")

# Sidebar pour les param√®tres
st.sidebar.header("Param√®tres de Mod√©lisation")

# Section de chargement des donn√©es
st.sidebar.subheader("üìä Donn√©es")
data_source = st.sidebar.radio(
    "Source des donn√©es:",
    ["Donn√©es d'exemple", "Charger un fichier CSV"]
)

# Chargement des donn√©es
@st.cache_data
def load_data(source_type, n_samples=200, uploaded_file=None):
    if source_type == "Donn√©es d'exemple":
        df = processor.create_sample_data(n_samples)
    else:
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
        else:
            return None
    
    return processor.load_and_preprocess_data(sample_data=df)

# Interface de chargement
if data_source == "Charger un fichier CSV":
    uploaded_file = st.sidebar.file_uploader(
        "Choisir un fichier CSV",
        type=['csv'],
        help="Le fichier doit contenir les colonnes: N¬∞ Anomalie, N¬∞ Tranche, D√©but_EUTM, D√©but_NUTM, Fin_EUTM, Fin_NUTM, Direction, Longueur (m), de (m), √† (m), √âpaisseur (m), Moyenne U (ppm), Max U (ppm), Lithologie"
    )
    
    if uploaded_file is not None:
        try:
            # Lecture initiale du fichier
            df_raw = pd.read_csv(uploaded_file)
            
            # Validation des donn√©es
            validator = DataValidator()
            errors, warnings = validator.validate_file_structure(df_raw)
            
            if errors:
                st.error("‚ùå Erreurs dans le fichier:")
                for error in errors:
                    st.error(f"‚Ä¢ {error}")
                df = None
            else:
                if warnings:
                    st.warning("‚ö†Ô∏è Avertissements:")
                    for warning in warnings:
                        st.warning(f"‚Ä¢ {warning}")
                
                # Nettoyage des donn√©es
                df_clean = validator.clean_data(df_raw)
                
                if len(df_clean) == 0:
                    st.error("‚ùå Aucune donn√©e valide apr√®s nettoyage.")
                    df = None
                else:
                    # Affichage du r√©sum√©
                    summary = validator.get_data_summary(df_clean)
                    st.success(f"‚úÖ Fichier charg√©: {summary['total_rows']} lignes, {len(df_clean)} lignes valides apr√®s nettoyage")
                    
                    df = load_data(data_source, uploaded_file=uploaded_file)
                    
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement du fichier: {str(e)}")
            st.info("üí° V√©rifiez que votre fichier CSV est correctement format√©.")
            df = None
    else:
        df = None
else:
    n_samples = st.sidebar.slider("Nombre d'√©chantillons", 50, 500, 200)
    try:
        df = load_data(data_source, n_samples=n_samples)
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la g√©n√©ration des donn√©es: {str(e)}")
        df = None

if df is not None:
    # Param√®tres de mod√©lisation
    st.sidebar.subheader("üîß Param√®tres ML")
    cutoff_grade = st.sidebar.slider("Teneur de coupure (ppm U)", 0, 100, 30)
    clustering_eps = st.sidebar.slider("Distance clustering (m)", 50, 500, 100)
    grid_resolution = st.sidebar.slider("R√©solution grille 3D", 20, 100, 50)
    
    # Traitement des donn√©es
    with st.spinner("Traitement des donn√©es en cours..."):
        # Clustering spatial
        df_clustered = processor.spatial_clustering(df, eps=clustering_eps)
        
        # Entra√Ænement du mod√®le ML
        model_results = processor.train_uranium_model(df_clustered)
        
        # Calcul des r√©serves
        reserves, ore_data = processor.calculate_ore_reserves(df_clustered, cutoff_grade)
        
        # Interpolation 3D
        interpolated_grids = processor.interpolate_3d_grid(df_clustered, grid_resolution)
    
    # Interface principale
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Donn√©es", "üéØ Mod√®le 3D", "üíé Corps Min√©ralis√©s", 
        "üß™ Analyse G√©ologique", "üìà R√©serves"
    ])
    
    with tab1:
        st.header("Donn√©es G√©ologiques")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("Aper√ßu des donn√©es")
            st.dataframe(df.head(20), use_container_width=True)
            
            # Statistiques descriptives
            st.subheader("Statistiques descriptives")
            numeric_cols = ['Moyenne U (ppm)', 'Max U (ppm)', '√âpaisseur (m)', 'Longueur (m)']
            st.dataframe(df[numeric_cols].describe(), use_container_width=True)
        
        with col2:
            st.subheader("Informations g√©n√©rales")
            st.metric("Nombre d'anomalies", len(df))
            st.metric("Nombre de clusters", df_clustered['Cluster'].nunique())
            st.metric("Lithologies", df['Lithologie'].nunique())
            
            st.subheader("Performance du mod√®le ML")
            st.metric("R¬≤ Score", f"{model_results['r2']:.3f}")
            st.metric("RMSE", f"{np.sqrt(model_results['mse']):.1f}")
            
            # Importance des features
            st.subheader("Importance des variables")
            importance_df = pd.DataFrame(
                list(model_results['feature_importance'].items()),
                columns=['Variable', 'Importance']
            ).sort_values('Importance', ascending=True)
            
            fig_importance = go.Figure(go.Bar(
                x=importance_df['Importance'],
                y=importance_df['Variable'],
                orientation='h'
            ))
            fig_importance.update_layout(
                title="Importance des Variables",
                height=300,
                margin=dict(l=0, r=0, t=30, b=0)
            )
            st.plotly_chart(fig_importance, use_container_width=True)
    
    with tab2:
        st.header("Mod√®le 3D du Gisement")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # Visualisation 3D principale
            color_option = st.selectbox(
                "Colorer par:",
                ['Moyenne U (ppm)', 'Max U (ppm)', '√âpaisseur (m)', 'Cluster']
            )
            
            size_option = st.selectbox(
                "Taille par:",
                ['√âpaisseur (m)', 'Longueur (m)', 'Moyenne U (ppm)']
            )
            
            fig_3d = visualizer.create_3d_scatter(df_clustered, color_option, size_option)
            st.plotly_chart(fig_3d, use_container_width=True)
        
        with col2:
            st.subheader("Contr√¥les de vue")
            
            show_interpolation = st.checkbox("Afficher surfaces interpol√©es", False)
            
            if show_interpolation:
                threshold = st.slider("Seuil d'affichage (ppm)", 0, 50, 20)
                fig_surfaces = visualizer.create_interpolated_surfaces(
                    interpolated_grids, threshold
                )
                st.plotly_chart(fig_surfaces, use_container_width=True)
            
            # Filtres
            st.subheader("Filtres")
            selected_lithologies = st.multiselect(
                "Lithologies:",
                df['Lithologie'].unique(),
                default=df['Lithologie'].unique()
            )
            
            min_grade = st.slider(
                "Teneur min (ppm):",
                float(df['Moyenne U (ppm)'].min()),
                float(df['Moyenne U (ppm)'].max()),
                float(df['Moyenne U (ppm)'].min())
            )
    
    with tab3:
        st.header("Corps Min√©ralis√©s")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            fig_ore = visualizer.create_ore_body_visualization(df_clustered, cutoff_grade)
            st.plotly_chart(fig_ore, use_container_width=True)
            
            # Courbe teneur-tonnage
            st.subheader("Courbe Teneur-Tonnage")
            fig_grade_tonnage = visualizer.create_grade_tonnage_curve(df_clustered)
            st.plotly_chart(fig_grade_tonnage, use_container_width=True)
        
        with col2:
            st.subheader("R√©serves Min√©rales")
            st.metric("Tonnage total", f"{reserves['total_tonnage']:,.0f} t")
            st.metric("Teneur moyenne", f"{reserves['average_grade']:.1f} ppm U")
            st.metric("Contenu m√©tal", f"{reserves['metal_content']:.2f} t U")
            st.metric("Blocs min√©ralis√©s", reserves['ore_blocks'])
            
            # Distribution des teneurs
            st.subheader("Distribution des teneurs")
            fig_hist = go.Figure(data=[
                go.Histogram(x=df_clustered['Moyenne U (ppm)'], nbinsx=30)
            ])
            fig_hist.add_vline(x=cutoff_grade, line_dash="dash", 
                              line_color="red", annotation_text="Seuil")
            fig_hist.update_layout(
                title="Distribution des teneurs",
                xaxis_title="Teneur U (ppm)",
                yaxis_title="Fr√©quence",
                height=300
            )
            st.plotly_chart(fig_hist, use_container_width=True)
    
    with tab4:
        st.header("Analyse G√©ologique")
        
        # Distribution des lithologies
        fig_litho = visualizer.create_lithology_distribution(df_clustered)
        st.plotly_chart(fig_litho, use_container_width=True)
        
        # Analyse par lithologie
        st.subheader("Statistiques par Lithologie")
        litho_stats = df_clustered.groupby('Lithologie').agg({
            'Moyenne U (ppm)': ['mean', 'std', 'count'],
            '√âpaisseur (m)': ['mean', 'std'],
            'Longueur (m)': ['mean', 'std']
        }).round(2)
        
        st.dataframe(litho_stats, use_container_width=True)
    
    with tab5:
        st.header("√âvaluation des R√©serves")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("R√©serves par Teneur de Coupure")
            
            # Calcul pour diff√©rentes teneurs
            cutoff_grades = np.arange(10, 101, 10)
            reserve_data = []
            
            for cutoff in cutoff_grades:
                res, _ = processor.calculate_ore_reserves(df_clustered, cutoff)
                reserve_data.append({
                    'Teneur de coupure': cutoff,
                    'Tonnage (t)': res['total_tonnage'],
                    'Teneur moyenne (ppm)': res['average_grade'],
                    'Contenu m√©tal (t)': res['metal_content']
                })
            
            reserve_df = pd.DataFrame(reserve_data)
            st.dataframe(reserve_df, use_container_width=True)
        
        with col2:
            st.subheader("Optimisation √âconomique")
            
            # Param√®tres √©conomiques
            uranium_price = st.number_input("Prix uranium ($/kg)", value=130.0)
            mining_cost = st.number_input("Co√ªt extraction ($/t)", value=50.0)
            processing_cost = st.number_input("Co√ªt traitement ($/t)", value=30.0)
            recovery = st.slider("R√©cup√©ration (%)", 0, 100, 85) / 100
            
            # Calcul de la valeur √©conomique
            reserve_df['Valeur brute ($)'] = (
                reserve_df['Contenu m√©tal (t)'] * 1000 * uranium_price * recovery
            )
            reserve_df['Co√ªt total ($)'] = (
                reserve_df['Tonnage (t)'] * (mining_cost + processing_cost)
            )
            reserve_df['Profit ($)'] = (
                reserve_df['Valeur brute ($)'] - reserve_df['Co√ªt total ($)']
            )
            
            # Teneur de coupure optimale
            optimal_cutoff = reserve_df.loc[reserve_df['Profit ($)'].idxmax(), 'Teneur de coupure']
            st.success(f"Teneur de coupure optimale: {optimal_cutoff} ppm U")
            
            # Graphique profit vs teneur
            fig_profit = go.Figure()
            fig_profit.add_trace(go.Scatter(
                x=reserve_df['Teneur de coupure'],
                y=reserve_df['Profit ($)'],
                mode='lines+markers',
                name='Profit'
            ))
            fig_profit.add_vline(x=optimal_cutoff, line_dash="dash", 
                                line_color="green", annotation_text="Optimal")
            fig_profit.update_layout(
                title="Profit vs Teneur de Coupure",
                xaxis_title="Teneur de coupure (ppm U)",
                yaxis_title="Profit ($)"
            )
            st.plotly_chart(fig_profit, use_container_width=True)
    
    # Export des r√©sultats
    st.sidebar.subheader("üíæ Export")
    if st.sidebar.button("T√©l√©charger les r√©sultats"):
        # Cr√©ation d'un fichier Excel avec plusieurs onglets
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_clustered.to_excel(writer, sheet_name='Donn√©es', index=False)
            reserve_df.to_excel(writer, sheet_name='R√©serves', index=False)
            ore_data.to_excel(writer, sheet_name='Minerai', index=False)
        
        st.sidebar.download_button(
            label="üì• T√©l√©charger Excel",
            data=output.getvalue(),
            file_name="resultats_gisement.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

else:
    st.warning("Veuillez charger des donn√©es pour commencer l'analyse.")
    
    # Instructions d'utilisation
    st.markdown("""
    ## üìã Instructions d'utilisation
    
    ### Format des donn√©es requis:
    Votre fichier CSV doit contenir les colonnes suivantes:
    - **N¬∞ Anomalie**: Identifiant unique de l'anomalie
    - **N¬∞ Tranche**: Num√©ro de la tranche
    - **D√©but_EUTM, D√©but_NUTM**: Coordonn√©es UTM de d√©but
    - **Fin_EUTM, Fin_NUTM**: Coordonn√©es UTM de fin
    - **Direction**: Direction en degr√©s
    - **Longueur (m)**: Longueur en m√®tres
    - **de (m), √† (m)**: Profondeur de d√©but et fin
    - **√âpaisseur (m)**: √âpaisseur en m√®tres
    - **Moyenne U (ppm), Max U (ppm)**: Teneurs en uranium
    - **Lithologie**: Type de roche
    
    ### Fonctionnalit√©s:
    - üéØ **Mod√©lisation 3D** avec machine learning
    - üíé **Identification des corps min√©ralis√©s**
    - üß™ **Analyse g√©ologique** par lithologie
    - üìà **√âvaluation des r√©serves** et optimisation √©conomique
    - üìä **Visualisations interactives** en 3D
    """)

# Footer
st.markdown("---")
st.markdown(
    "D√©velopp√© pour la mod√©lisation g√©ologique 3D | "
    "Utilise Streamlit, Plotly, Scikit-learn et Pandas"
)
